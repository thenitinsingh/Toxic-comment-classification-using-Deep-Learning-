{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfdfuY-UaIex",
        "outputId": "c41283aa-cd60-4d16-c830-c6c155c996c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdYscuklskqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yAlhHy-YX61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416f912b-3543-4d06-96f1-197e5544861b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (0.41)\n",
            "Requirement already satisfied: polyglot in /usr/local/lib/python3.10/dist-packages (16.7.4)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.15.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.5.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install polyglot\n",
        "!pip install textstat\n",
        "!pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg9RCw_XTTUq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import folium\n",
        "import textstat\n",
        "from scipy import stats\n",
        "from colorama import Fore, Back, Style, init\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import networkx as nx\n",
        "from pandas import Timestamp\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot\n",
        "\n",
        "import requests\n",
        "from IPython.display import HTML\n",
        "\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Embedding\n",
        "from tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import constraints\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.constraints import *\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.regularizers import *\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,\\\n",
        "                                            CountVectorizer,\\\n",
        "                                            HashingVectorizer\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from googletrans import Translator\n",
        "from nltk import WordNetLemmatizer\n",
        "from polyglot.detect import Detector\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "stopword=set(STOPWORDS)\n",
        "\n",
        "lem = WordNetLemmatizer()\n",
        "tokenizer=TweetTokenizer()\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "caNBTnJCZON9",
        "outputId": "57ea2291-349c-4025-89f2-f764104ef671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a91b939-c7c1-4da5-8f9d-fa2dd541c178\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a91b939-c7c1-4da5-8f9d-fa2dd541c178\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving jigsaw-toxic-comment-train.csv.zip to jigsaw-toxic-comment-train.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "j5XyT93iZPnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for zip_filename in uploaded.keys():\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        # Extract all contents to a temporary directory\n",
        "        zip_ref.extractall('temp_extracted')\n",
        "\n",
        "# Move the CSV file to the root folder\n",
        "csv_file_path = 'temp_extracted/jigsaw-toxic-comment-train/jigsaw-toxic-comment-train.csv'\n",
        "if os.path.exists(csv_file_path):\n",
        "    os.rename(csv_file_path, 'jigsaw-toxic-comment-train.csv')"
      ],
      "metadata": {
        "id": "ZeCzA2UMpcvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('temp_extracted/jigsaw-toxic-comment-train.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "F8oCxoK_pmw3",
        "outputId": "78ab7c04-1fd9-4579-d580-d96b17734e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
              "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
              "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
              "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
              "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
              "...                  ...                                                ...   \n",
              "223544  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n",
              "223545  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
              "223546  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
              "223547  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
              "223548  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "223544      0             0        0       0       0              0  \n",
              "223545      0             0        0       0       0              0  \n",
              "223546      0             0        0       0       0              0  \n",
              "223547      1             0        1       0       1              0  \n",
              "223548      0             0        0       0       0              0  \n",
              "\n",
              "[223549 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8071ff1b-368d-4777-a83c-8f3fd2b7218e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223544</th>\n",
              "      <td>fff8f64043129fa2</td>\n",
              "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223545</th>\n",
              "      <td>fff9d70fe0722906</td>\n",
              "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223546</th>\n",
              "      <td>fffa8a11c4378854</td>\n",
              "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223547</th>\n",
              "      <td>fffac2a094c8e0e2</td>\n",
              "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223548</th>\n",
              "      <td>fffb5451268fb5ba</td>\n",
              "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223549 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8071ff1b-368d-4777-a83c-8f3fd2b7218e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8071ff1b-368d-4777-a83c-8f3fd2b7218e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8071ff1b-368d-4777-a83c-8f3fd2b7218e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06b98479-3cf1-4227-a92e-af10e0b87a83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06b98479-3cf1-4227-a92e-af10e0b87a83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06b98479-3cf1-4227-a92e-af10e0b87a83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c847f8f6-e8da-454c-b9bd-d9e48248cabf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c847f8f6-e8da-454c-b9bd-d9e48248cabf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Move files from temp_extracted directory to main directory\n",
        "temp_extracted_dir = 'temp_extracted'\n",
        "main_dir = '.'\n",
        "\n",
        "# List files in the temp_extracted directory\n",
        "files_to_move = os.listdir(temp_extracted_dir)\n",
        "\n",
        "# Move each file to the main directory\n",
        "for file in files_to_move:\n",
        "    src = os.path.join(temp_extracted_dir, file)\n",
        "    dst = os.path.join(main_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "# Remove the temp_extracted directory\n",
        "os.rmdir('temp_extracted')"
      ],
      "metadata": {
        "id": "SJFyYACGsQFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "pli-ECwqqhVJ",
        "outputId": "740f8045-a117-483d-f039-f775d83144fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b72e704-d473-448d-9127-be6afbbb9bae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b72e704-d473-448d-9127-be6afbbb9bae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test.csv\n",
            "Saving validation.csv to validation.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in the root folder\n",
        "files = os.listdir('.')\n",
        "print(\"Files in the root folder:\")\n",
        "for file in files:\n",
        "    print(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsB2L23mrutR",
        "outputId": "6f6e1a8d-570e-40cb-d7ea-ff19081b0507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the root folder:\n",
            ".config\n",
            "validation.csv\n",
            "jigsaw-toxic-comment-train.csv.zip\n",
            "test.csv\n",
            "jigsaw-toxic-comment-train.csv\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path configs\n",
        "TEST_PATH =\"test.csv\"\n",
        "VAL_PATH =\"validation.csv\"\n",
        "TRAIN_PATH =\"jigsaw-toxic-comment-train.csv\"\n",
        "\n",
        "val_data = pd.read_csv(VAL_PATH)\n",
        "test_data = pd.read_csv(TEST_PATH)\n",
        "train_data = pd.read_csv(TRAIN_PATH)\n"
      ],
      "metadata": {
        "id": "_QzhI3FetH09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = val_data\n",
        "train = train_data\n",
        "\n",
        "def clean(text):\n",
        "    text = text.fillna(\"fillna\").str.lower()\n",
        "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
        "    return text\n",
        "\n",
        "val[\"comment_text\"] = clean(val[\"comment_text\"])\n",
        "test_data[\"content\"] = clean(test_data[\"content\"])\n",
        "train[\"comment_text\"] = clean(train[\"comment_text\"])"
      ],
      "metadata": {
        "id": "bLiuc6MPtbrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = rocaucscore(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
      ],
      "metadata": {
        "id": "RrRpiw3etxT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_encode(texts, tokenizer, chunk_size=240, maxlen=512):\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding(max_length=maxlen)\n",
        "    all_ids = []\n",
        "\n",
        "    for i in range(0, len(texts), chunk_size):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encs = tokenizer.encode_batch(text_chunk)\n",
        "        all_ids.extend([enc.ids for enc in encs])\n",
        "\n",
        "    return np.array(all_ids)"
      ],
      "metadata": {
        "id": "AEFK74eSt4Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set AUTOTUNE for optimization\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Update the GCS_DS_PATH with the path to your dataset in Google Colab\n",
        "GCS_DS_PATH = '/content/'\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Continue with the rest of your code...\n"
      ],
      "metadata": {
        "id": "qyy_dKDzt8Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "import os\n",
        "\n",
        "# Initialize the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "# Define the path to save the tokenizer\n",
        "SAVE_PATH = \"/content/model/\"\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "\n",
        "# Save the tokenizer to the specified directory\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "\n",
        "# Initialize the tokenizer for fast tokenization\n",
        "fast_tokenizer = DistilBertTokenizer.from_pretrained(SAVE_PATH, lowercase=True)\n"
      ],
      "metadata": {
        "id": "MX2YmtPKzxPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_encode(texts, tokenizer, chunk_size=240, maxlen=512):\n",
        "    all_ids = []\n",
        "    for i in range(0, len(texts), chunk_size):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encodings = tokenizer(text_chunk, max_length=maxlen, padding='max_length', truncation=True)\n",
        "        all_ids.extend(encodings['input_ids'])\n",
        "    return np.array(all_ids)\n"
      ],
      "metadata": {
        "id": "HeIUt2vr07EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Remove TPU setup since it's not available in Google Colab\n",
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "# Instead, use GPU acceleration if available\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU is available')\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define GCS path to the dataset\n",
        "GCS_DS_PATH = '/content/'\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "k6lYmhs71HoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "\n",
        "# Load the fast tokenizer\n",
        "fast_tokenizer = BertWordPieceTokenizer('/content/working/distilbert_base_uncased/vocab.txt', lowercase=True)"
      ],
      "metadata": {
        "id": "RPq3tTDf9TEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_encode(texts, tokenizer, chunk_size=240, maxlen=512):\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding(max_length=maxlen)\n",
        "    all_ids = []\n",
        "\n",
        "    for i in range(0, len(texts), chunk_size):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encs = tokenizer.encode_batch(text_chunk)\n",
        "        all_ids.extend([enc.ids for enc in encs])\n",
        "\n",
        "    return np.array(all_ids)\n"
      ],
      "metadata": {
        "id": "GV9IZIYq_4_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def fast_encode(texts, tokenizer, maxlen=512):\n",
        "    all_ids = []\n",
        "\n",
        "    for text in texts:\n",
        "        encodings = tokenizer.encode(text)\n",
        "        all_ids.append(encodings.ids)\n",
        "\n",
        "    padded_ids = pad_sequences(all_ids, maxlen=maxlen, padding='post', truncating='post')\n",
        "    return padded_ids"
      ],
      "metadata": {
        "id": "7v3XSKIDAfxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the training, validation, and test data\n",
        "x_train = fast_encode(train.comment_text.astype(str), fast_tokenizer, maxlen=512)\n",
        "x_valid= fast_encode(val.comment_text.astype(str).values, fast_tokenizer, maxlen=512)\n",
        "x_test= fast_encode(test_data.content.astype(str).values, fast_tokenizer, maxlen=512)\n",
        "\n",
        "# Define the labels for validation and training datasets\n",
        "y_valid = val.toxic.values\n",
        "y_train = train.toxic.values"
      ],
      "metadata": {
        "id": "r5orfESAAk3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_valid, y_valid))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(x_test)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "KpgSXxElBezJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x"
      ],
      "metadata": {
        "id": "UeALT350JMSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XsYJsNdkB7IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Capsule(Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 initializer='glorot_uniform',\n",
        "                 activation=None,\n",
        "                 regularizer=None,\n",
        "                 constraint=None,\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "\n",
        "        self.activation = activations.get(activation)\n",
        "        self.regularizer = regularizers.get(regularizer)\n",
        "        self.initializer = initializers.get(initializer)\n",
        "        self.constraint = constraints.get(constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.W = self.add_weight(name='capsule_kernel',\n",
        "                                     shape=(1,\n",
        "                                            input_dim_capsule,\n",
        "                                            self.num_capsule *\n",
        "                                            self.dim_capsule),\n",
        "                                     initializer=self.initializer,\n",
        "                                     regularizer=self.regularizer,\n",
        "                                     constraint=self.constraint,\n",
        "                                     trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.W = self.add_weight(name='capsule_kernel',\n",
        "                                     shape=(input_num_capsule,\n",
        "                                            input_dim_capsule,\n",
        "                                            self.num_capsule *\n",
        "                                            self.dim_capsule),\n",
        "                                     initializer=self.initializer,\n",
        "                                     regularizer=self.regularizer,\n",
        "                                     constraint=self.constraint,\n",
        "                                     trainable=True)\n",
        "\n",
        "        self.build = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.share_weights:\n",
        "            u_hat_vectors = K.conv1d(inputs, self.W)\n",
        "        else:\n",
        "            u_hat_vectors = K.local_conv1d(inputs, self.W, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        u_hat_vectors = K.reshape(u_hat_vectors, (batch_size,\n",
        "                                                  input_num_capsule,\n",
        "                                                  self.num_capsule,\n",
        "                                                  self.dim_capsule))\n",
        "\n",
        "        u_hat_vectors = K.permute_dimensions(u_hat_vectors, (0, 2, 1, 3))\n",
        "        routing_weights = K.zeros_like(u_hat_vectors[:, :, :, 0])\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            capsule_weights = K.softmax(routing_weights, 1)\n",
        "            outputs = K.batch_dot(capsule_weights, u_hat_vectors, [2, 2])\n",
        "            if K.ndim(outputs) == 4:\n",
        "                outputs = K.sum(outputs, axis=1)\n",
        "            if i < self.routings - 1:\n",
        "                outputs = K.l2_normalize(outputs, -1)\n",
        "                routing_weights = K.batch_dot(outputs, u_hat_vectors, [2, 3])\n",
        "                if K.ndim(routing_weights) == 4:\n",
        "                    routing_weights = K.sum(routing_weights, axis=1)\n",
        "\n",
        "        return self.activation(outputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)"
      ],
      "metadata": {
        "id": "jP-7mUCsKE-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_capsule_model(transformer, max_len):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "    embed = transformer.weights[0].numpy()\n",
        "    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n",
        "                          input_length=max_len, weights=[embed],\n",
        "                          trainable=False)(input_word_ids)\n",
        "\n",
        "    embedding = SpatialDropout1D(0.3)(embedding)\n",
        "    capsule = Capsule(num_capsule=5, dim_capsule=5,\n",
        "                      routings=4, activation=squash)(embedding)\n",
        "\n",
        "    capsule = Flatten()(capsule)\n",
        "    output = Dense(128, activation='relu')(capsule)\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs=input_word_ids, outputs=output)\n",
        "\n",
        "    model.compile(Adam(lr=1.5e-5),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HhkJbbcECMme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "o9C6OB3nClaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_suDGKFHgUQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    transformer_layer = (transformers.TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased'))\n",
        "    model = custom_capsule_model(transformer_layer, max_len=512)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNf_VEZCCTju",
        "outputId": "dd9e029c-d721-4592-f43a-e61501d61bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer  [(None, 512)]             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 512, 768)          91812096  \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spati  (None, 512, 768)          0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " capsule_1 (Capsule)         (None, 5, 5)              19200     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               3328      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91834753 (350.32 MB)\n",
            "Trainable params: 22657 (88.50 KB)\n",
            "Non-trainable params: 91812096 (350.24 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "nhDqinWYSmu8",
        "outputId": "d7a6d7b7-084d-47bc-cb28-5b6c82647ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"245pt\" height=\"470pt\" viewBox=\"0.00 0.00 252.00 483.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1.03 1.03) rotate(0) translate(4 479)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-479 248,-479 248,4 -4,4\"/>\n<!-- 135392601741376 -->\n<g id=\"node1\" class=\"node\">\n<title>135392601741376</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"33,-438.5 33,-474.5 211,-474.5 211,-438.5 33,-438.5\"/>\n<text text-anchor=\"middle\" x=\"83.5\" y=\"-452.8\" font-family=\"Times,serif\" font-size=\"14.00\">input_word_ids</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"134,-438.5 134,-474.5 \"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-452.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n</g>\n<!-- 135391916616736 -->\n<g id=\"node2\" class=\"node\">\n<title>135391916616736</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"36.5,-365.5 36.5,-401.5 207.5,-401.5 207.5,-365.5 36.5,-365.5\"/>\n<text text-anchor=\"middle\" x=\"82\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\">embedding_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"127.5,-365.5 127.5,-401.5 \"/>\n<text text-anchor=\"middle\" x=\"167.5\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n</g>\n<!-- 135392601741376&#45;&gt;135391916616736 -->\n<g id=\"edge1\" class=\"edge\">\n<title>135392601741376-&gt;135391916616736</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-438.31C122,-430.29 122,-420.55 122,-411.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-411.53 122,-401.53 118.5,-411.53 125.5,-411.53\"/>\n</g>\n<!-- 135391684565296 -->\n<g id=\"node3\" class=\"node\">\n<title>135391684565296</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-292.5 0,-328.5 244,-328.5 244,-292.5 0,-292.5\"/>\n<text text-anchor=\"middle\" x=\"64\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">spatial_dropout1d_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"128,-292.5 128,-328.5 \"/>\n<text text-anchor=\"middle\" x=\"186\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">SpatialDropout1D</text>\n</g>\n<!-- 135391916616736&#45;&gt;135391684565296 -->\n<g id=\"edge2\" class=\"edge\">\n<title>135391916616736-&gt;135391684565296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-365.31C122,-357.29 122,-347.55 122,-338.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-338.53 122,-328.53 118.5,-338.53 125.5,-338.53\"/>\n</g>\n<!-- 135392508696688 -->\n<g id=\"node4\" class=\"node\">\n<title>135392508696688</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"56.5,-219.5 56.5,-255.5 187.5,-255.5 187.5,-219.5 56.5,-219.5\"/>\n<text text-anchor=\"middle\" x=\"92\" y=\"-233.8\" font-family=\"Times,serif\" font-size=\"14.00\">capsule_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"127.5,-219.5 127.5,-255.5 \"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-233.8\" font-family=\"Times,serif\" font-size=\"14.00\">Capsule</text>\n</g>\n<!-- 135391684565296&#45;&gt;135392508696688 -->\n<g id=\"edge3\" class=\"edge\">\n<title>135391684565296-&gt;135392508696688</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-292.31C122,-284.29 122,-274.55 122,-265.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-265.53 122,-255.53 118.5,-265.53 125.5,-265.53\"/>\n</g>\n<!-- 135391916545536 -->\n<g id=\"node5\" class=\"node\">\n<title>135391916545536</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"62.5,-146.5 62.5,-182.5 181.5,-182.5 181.5,-146.5 62.5,-146.5\"/>\n<text text-anchor=\"middle\" x=\"95\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">flatten_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"127.5,-146.5 127.5,-182.5 \"/>\n<text text-anchor=\"middle\" x=\"154.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten</text>\n</g>\n<!-- 135392508696688&#45;&gt;135391916545536 -->\n<g id=\"edge4\" class=\"edge\">\n<title>135392508696688-&gt;135391916545536</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-219.31C122,-211.29 122,-201.55 122,-192.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-192.53 122,-182.53 118.5,-192.53 125.5,-192.53\"/>\n</g>\n<!-- 135392508693472 -->\n<g id=\"node6\" class=\"node\">\n<title>135392508693472</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-73.5 66.5,-109.5 177.5,-109.5 177.5,-73.5 66.5,-73.5\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"127.5,-73.5 127.5,-109.5 \"/>\n<text text-anchor=\"middle\" x=\"152.5\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 135391916545536&#45;&gt;135392508693472 -->\n<g id=\"edge5\" class=\"edge\">\n<title>135391916545536-&gt;135392508693472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-146.31C122,-138.29 122,-128.55 122,-119.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-119.53 122,-109.53 118.5,-119.53 125.5,-119.53\"/>\n</g>\n<!-- 135397518630176 -->\n<g id=\"node7\" class=\"node\">\n<title>135397518630176</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-0.5 66.5,-36.5 177.5,-36.5 177.5,-0.5 66.5,-0.5\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_3</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"127.5,-0.5 127.5,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"152.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 135392508693472&#45;&gt;135397518630176 -->\n<g id=\"edge6\" class=\"edge\">\n<title>135392508693472-&gt;135397518630176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-73.31C122,-65.29 122,-55.55 122,-46.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-46.53 122,-36.53 118.5,-46.53 125.5,-46.53\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def callback():\n",
        "    cb = []\n",
        "\n",
        "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                    factor=0.3, patience=3,\n",
        "                                    verbose=1, mode='auto',\n",
        "                                    epsilon=0.0001, cooldown=1, min_lr=0.000001)\n",
        "    cb.append(reduceLROnPlat)\n",
        "    log = CSVLogger('log.csv')\n",
        "    cb.append(log)\n",
        "\n",
        "    RocAuc = RocAucEvaluation(validation_data=(x_valid, y_valid), interval=1)\n",
        "    cb.append(RocAuc)\n",
        "\n",
        "    return cb"
      ],
      "metadata": {
        "id": "TOjsYqroS1q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def rocaucscore(y_true, y_pred):\n",
        "    return roc_auc_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "cXhiKI4SmbaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_STEPS = x_train.shape[0] // BATCH_SIZE\n",
        "calls = callback()\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=N_STEPS,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks = calls,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zPP1tWSS806",
        "outputId": "323d209d-ef79-43cc-be93-dc2332327dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "3492/3492 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.9061\n",
            " ROC-AUC - epoch: 1 - score: 0.547604\n",
            "3492/3492 [==============================] - 610s 175ms/step - loss: 0.2863 - accuracy: 0.9061 - val_loss: 0.5103 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 2/2\n",
            "3492/3492 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9059\n",
            " ROC-AUC - epoch: 2 - score: 0.557567\n",
            "3492/3492 [==============================] - 610s 175ms/step - loss: 0.2828 - accuracy: 0.9059 - val_loss: 0.4533 - val_accuracy: 0.8399 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "\n",
        "def visualize_model_preds(model, indices=[0, 17, 1, 24]):\n",
        "    comments = val_data.comment_text.loc[indices].values.tolist()\n",
        "    preds = model.predict(x_valid[indices].reshape(len(indices), -1))\n",
        "\n",
        "    for idx, i in enumerate(indices):\n",
        "        if y_valid[i] == 0:\n",
        "            label = \"Non-toxic\"\n",
        "            color = f'{Fore.GREEN}'\n",
        "            symbol = '\\u2714'\n",
        "        else:\n",
        "            label = \"Toxic\"\n",
        "            color = f'{Fore.RED}'\n",
        "            symbol = '\\u2716'\n",
        "\n",
        "        print('{}{} {}'.format(color, str(idx+1) + \". \" + label, symbol))\n",
        "        print(f'{Style.RESET_ALL}')\n",
        "        print(\"ORIGINAL\")\n",
        "        print(comments[idx]); print(\"\")\n",
        "        print(\"TRANSLATED\")\n",
        "        print(translator.translate(comments[idx]).text)\n",
        "        fig = go.Figure()\n",
        "        if list.index(sorted(preds[:, 0]), preds[idx][0]) > 1:\n",
        "            yl = [preds[idx][0], 1 - preds[idx][0]]\n",
        "        else:\n",
        "            yl = [1 - preds[idx][0], preds[idx][0]]\n",
        "        fig.add_trace(go.Bar(x=['Non-Toxic', 'Toxic'], y=yl, marker=dict(color=[\"seagreen\", \"indianred\"])))\n",
        "        fig.update_traces(name=comments[idx])\n",
        "        fig.update_layout(xaxis_title=\"Labels\", yaxis_title=\"Probability\", template=\"plotly_white\", title_text=\"Predictions for validation comment #{}\".format(idx+1))\n",
        "        fig.show()\n",
        "\n",
        "\n",
        "visualize_model_preds(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "TGkqTsaMrpjk",
        "outputId": "00206128-0ba6-4553-a56a-9faf1478892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "\u001b[32m1. Non-toxic ✔\n",
            "\u001b[0m\n",
            "ORIGINAL\n",
            "este usuario ni siquiera llega al rango de    hereje   . por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    skipe linkin 22px   honor, valor, leltad.      17:48 13 mar 2008 (utc)\n",
            "\n",
            "TRANSLATED\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'group'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-baa5763079df>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mvisualize_model_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-88-baa5763079df>\u001b[0m in \u001b[0;36mvisualize_model_preds\u001b[0;34m(model, indices)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRANSLATED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_acquirer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         params = utils.build_params(query=text, src=src, dest=dest,\n\u001b[1;32m     80\u001b[0m                                     token=token, override=override)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# this will be the same as python code after stripping out a reserved word 'var'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode-escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bvpRNDw2Cmrx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}